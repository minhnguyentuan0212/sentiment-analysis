{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"word2vec+cnn_v3.ipynb","provenance":[{"file_id":"1rFZZf9ECknkLNDv8so_kQNPhqain0RqJ","timestamp":1653989613942}]},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"sQic7KJRaSP6","executionInfo":{"status":"ok","timestamp":1653989276555,"user_tz":-420,"elapsed":22959,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"}},"outputId":"ecec867d-34a0-4c95-d5d8-d51e999e0ff3","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install pyvi"],"metadata":{"id":"aoVjFKmOZMZ8","executionInfo":{"status":"ok","timestamp":1653989252196,"user_tz":-420,"elapsed":4639,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"}},"outputId":"bcd119ff-e091-4cf5-ca96-45e131211e1e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyvi\n","  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n","\u001b[K     |████████████████████████████████| 8.5 MB 7.2 MB/s \n","\u001b[?25hCollecting sklearn-crfsuite\n","  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyvi) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.4.1)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.21.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyvi) (1.1.0)\n","Collecting python-crfsuite>=0.8.3\n","  Downloading python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (965 kB)\n","\u001b[K     |████████████████████████████████| 965 kB 64.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (4.64.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n","Successfully installed python-crfsuite-0.9.8 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n"]}]},{"cell_type":"code","metadata":{"id":"8TFX7wSAmg9y"},"source":["import tensorflow as tf\n","import pandas as pd \n","import numpy as np\n","from string import digits\n","from collections import Counter\n","from pyvi import ViTokenizer\n","from gensim.models.word2vec import Word2Vec\n","from keras.utils.np_utils import to_categorical\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"a7lMy03omg93"},"source":["data_train = pd.read_csv(\"vlsp_sentiment_train.csv\", sep='\\t')\n","data_train.columns =['Class', 'Data']\n","data_test = pd.read_csv(\"vlsp_sentiment_test.csv\", sep='\\t')\n","data_test.columns =['Class', 'Data']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4HR1jAzImg94","executionInfo":{"status":"ok","timestamp":1653989301990,"user_tz":-420,"elapsed":944,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"}},"outputId":"8e324c8c-0dbb-4a69-aeff-b03e40766c7e","colab":{"base_uri":"https://localhost:8080/"}},"source":["print(data_train.shape)\n","print(data_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(5100, 2)\n","(1050, 2)\n"]}]},{"cell_type":"code","metadata":{"id":"jvrbwPfZmg95"},"source":["labels = data_train.iloc[:, 0].values\n","reviews = data_train.iloc[:, 1].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3HlbVeHimg95"},"source":["encoded_labels = []\n","\n","for label in labels:\n","    if label == -1:\n","        encoded_labels.append([1,0,0])\n","    elif label == 0:\n","        encoded_labels.append([0,1,0])\n","    else:\n","        encoded_labels.append([0,0,1])\n","\n","encoded_labels = np.array(encoded_labels)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lm4OCwxXmg96"},"source":["reviews_processed = []\n","unlabeled_processed = [] \n","for review in reviews:\n","    review_cool_one = ''.join([char for char in review if char not in digits])\n","    reviews_processed.append(review_cool_one)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nW2OZgkgmg97"},"source":["#Use PyVi for Vietnamese word tokenizer\n","word_reviews = []\n","all_words = []\n","for review in reviews_processed:\n","    review = ViTokenizer.tokenize(review.lower())\n","    word_reviews.append(review.split())\n","   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTb0MeDRmg98"},"source":["EMBEDDING_DIM = 400 # how big is each word vector\n","MAX_VOCAB_SIZE = 10000 # how many unique words to use (i.e num rows in embedding vector)\n","MAX_SEQUENCE_LENGTH = 300 # max number of words in a comment to use"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jW-7mKtWmg9-"},"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BHpPSLTmg9_"},"source":["tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, lower=True, char_level=False)\n","tokenizer.fit_on_texts(word_reviews)\n","sequences_train = tokenizer.texts_to_sequences(word_reviews)\n","word_index = tokenizer.word_index\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlV3M2dimg9_"},"source":["data = pad_sequences(sequences_train, maxlen=MAX_SEQUENCE_LENGTH)\n","labels = encoded_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dl9VZ3Rmg-A","outputId":"0d43e170-e903-4d5b-f3ec-18a8b911d072","executionInfo":{"status":"ok","timestamp":1653989306259,"user_tz":-420,"elapsed":11,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Shape of X train and X validation tensor:',data.shape)\n","print('Shape of label train and validation tensor:', labels.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X train and X validation tensor: (5100, 300)\n","Shape of label train and validation tensor: (5100, 3)\n"]}]},{"cell_type":"code","metadata":{"id":"-KKSjJdJmg-A"},"source":["import gensim\n","from gensim.models import Word2Vec\n","from gensim.utils import simple_preprocess\n","\n","from gensim.models.keyedvectors import KeyedVectors\n","\n","word_vectors = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Tài liệu HCMUT/Cách tiếp cận hiện đại trong xử lý ngôn ngữ tự nhiên/CNN+W2V_Sentiment Analysis/vi-model-CBOW.bin', binary=True)\n","\n","\n","vocabulary_size=min(len(word_index)+1,MAX_VOCAB_SIZE)\n","embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n","for word, i in word_index.items():\n","    if i>=MAX_VOCAB_SIZE:\n","        continue\n","    try:\n","        embedding_vector = word_vectors[word]\n","        embedding_matrix[i] = embedding_vector\n","    except KeyError:\n","        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n","\n","del(word_vectors)\n","\n","from keras.layers import Embedding\n","embedding_layer = Embedding(vocabulary_size,\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            trainable=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"njBANdn5mg-B","outputId":"24647910-9144-4987-83a2-fe64e64a04ac","executionInfo":{"status":"ok","timestamp":1653989417080,"user_tz":-420,"elapsed":381,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Embedding, Dropout,concatenate\n","from tensorflow.keras.layers import Reshape, Flatten\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import regularizers\n","sequence_length = data.shape[1]\n","filter_sizes = [3,4,5]\n","num_filters = 100\n","drop = 0.5\n","\n","inputs = Input(shape=(sequence_length,))\n","embedding = embedding_layer(inputs)\n","# reshape = Reshape((sequence_length,EMBEDDING_DIM,1))(embedding)\n","\n","conv_0 = Conv1D(num_filters, filter_sizes[0],activation='relu',kernel_regularizer=regularizers.l2(0.01))(embedding)\n","conv_1 = Conv1D(num_filters, filter_sizes[1],activation='relu',kernel_regularizer=regularizers.l2(0.01))(embedding)\n","conv_2 = Conv1D(num_filters, filter_sizes[2],activation='relu',kernel_regularizer=regularizers.l2(0.01))(embedding)\n","print(conv_1)\n","maxpool_0 = MaxPooling1D(sequence_length - filter_sizes[0] + 1, strides=1)(conv_0)\n","maxpool_1 = MaxPooling1D(sequence_length - filter_sizes[1] + 1, strides=1)(conv_1)\n","maxpool_2 = MaxPooling1D(sequence_length - filter_sizes[2] + 1, strides=1)(conv_2)\n","\n","merged_tensor = concatenate([maxpool_0, maxpool_1, maxpool_2], axis=1)\n","flatten = Flatten()(merged_tensor)\n","reshape = Reshape((3*num_filters,))(flatten)\n","dropout = Dropout(drop)(flatten)\n","output = Dense(units=3, activation='softmax',kernel_regularizer=regularizers.l2(0.01))(dropout)\n","\n","\n","# this creates a model that includes\n","model = Model(inputs, output)\n","\n","\n","adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n","model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n","model.summary()\n","\n","#define callbacks\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n","callbacks_list = [early_stopping]\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, 297, 100), dtype=tf.float32, name=None), name='conv1d_4/Relu:0', description=\"created by layer 'conv1d_4'\")\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 300)]        0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, 300, 400)     3167600     ['input_2[0][0]']                \n","                                                                                                  \n"," conv1d_3 (Conv1D)              (None, 298, 100)     120100      ['embedding[1][0]']              \n","                                                                                                  \n"," conv1d_4 (Conv1D)              (None, 297, 100)     160100      ['embedding[1][0]']              \n","                                                                                                  \n"," conv1d_5 (Conv1D)              (None, 296, 100)     200100      ['embedding[1][0]']              \n","                                                                                                  \n"," max_pooling1d_3 (MaxPooling1D)  (None, 1, 100)      0           ['conv1d_3[0][0]']               \n","                                                                                                  \n"," max_pooling1d_4 (MaxPooling1D)  (None, 1, 100)      0           ['conv1d_4[0][0]']               \n","                                                                                                  \n"," max_pooling1d_5 (MaxPooling1D)  (None, 1, 100)      0           ['conv1d_5[0][0]']               \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 3, 100)       0           ['max_pooling1d_3[0][0]',        \n","                                                                  'max_pooling1d_4[0][0]',        \n","                                                                  'max_pooling1d_5[0][0]']        \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 300)          0           ['concatenate_1[0][0]']          \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 300)          0           ['flatten_1[0][0]']              \n","                                                                                                  \n"," dense_1 (Dense)                (None, 3)            903         ['dropout_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 3,648,803\n","Trainable params: 3,648,803\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","metadata":{"id":"Jn0dBlzjmg-D","outputId":"be7de957-bf78-4fff-bc31-b5e586f705fa","executionInfo":{"status":"ok","timestamp":1653989547863,"user_tz":-420,"elapsed":10375,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["model.fit(data, labels, validation_split=0.2,\n","          epochs=5, batch_size=256, callbacks=callbacks_list, shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","16/16 [==============================] - 2s 130ms/step - loss: 0.4944 - accuracy: 0.9784 - val_loss: 2.4030 - val_accuracy: 0.1706\n","Epoch 2/5\n","16/16 [==============================] - 2s 127ms/step - loss: 0.4781 - accuracy: 0.9755 - val_loss: 2.7319 - val_accuracy: 0.0882\n","Epoch 3/5\n","16/16 [==============================] - 2s 128ms/step - loss: 0.4636 - accuracy: 0.9748 - val_loss: 2.2442 - val_accuracy: 0.1882\n","Epoch 4/5\n","16/16 [==============================] - 2s 127ms/step - loss: 0.4541 - accuracy: 0.9733 - val_loss: 2.2611 - val_accuracy: 0.1833\n","Epoch 5/5\n","16/16 [==============================] - 2s 127ms/step - loss: 0.4349 - accuracy: 0.9777 - val_loss: 2.4392 - val_accuracy: 0.1451\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1817995450>"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"8XoN2UOamg-D"},"source":["labels_test = data_test.iloc[:, 0].values\n","reviews_test = data_test.iloc[:, 1].values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PwiYb3Ohmg-E"},"source":["encoded_labels_test = []\n","\n","for label_test in labels_test:\n","    if label_test == -1:\n","        encoded_labels_test.append([1,0,0])\n","    elif label_test == 0:\n","        encoded_labels_test.append([0,1,0])\n","    else:\n","        encoded_labels_test.append([0,0,1])\n","\n","encoded_labels_test = np.array(encoded_labels_test)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E08tBw9img-E"},"source":["reviews_processed_test = []\n","unlabeled_processed_test = [] \n","for review_test in reviews_test:\n","    review_cool_one = ''.join([char for char in review_test if char not in digits])\n","    reviews_processed_test.append(review_cool_one)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OwgI9Xywmg-E"},"source":["#Use PyVi for Vietnamese word tokenizer\n","word_reviews_test = []\n","all_words = []\n","for review_test in reviews_processed_test:\n","    review_test = ViTokenizer.tokenize(review_test.lower())\n","    word_reviews_test.append(review_test.split())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p02GxCh6mg-F"},"source":["sequences_test = tokenizer.texts_to_sequences(word_reviews_test)\n","data_test = pad_sequences(sequences_test, maxlen=MAX_SEQUENCE_LENGTH)\n","labels_test = encoded_labels_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAqUMGInmg-F","outputId":"40acf056-b9c9-42ed-c767-423cc2054383","executionInfo":{"status":"ok","timestamp":1653989480441,"user_tz":-420,"elapsed":534,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["print('Shape of X train and X validation tensor:',data_test.shape)\n","print('Shape of label train and validation tensor:', labels_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X train and X validation tensor: (1050, 300)\n","Shape of label train and validation tensor: (1050, 3)\n"]}]},{"cell_type":"code","metadata":{"id":"LKclttiOmg-F","outputId":"6abe8e2e-7ed4-439f-8899-e6b30a044758","executionInfo":{"status":"ok","timestamp":1653989548454,"user_tz":-420,"elapsed":596,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["score = model.evaluate(data_test, labels_test)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["33/33 [==============================] - 0s 6ms/step - loss: 1.2146 - accuracy: 0.6505\n"]}]},{"cell_type":"code","metadata":{"id":"r31_uxxgmg-G","outputId":"2fb9d570-546b-4652-ca5f-5e6794fc6198","executionInfo":{"status":"ok","timestamp":1653989552805,"user_tz":-420,"elapsed":355,"user":{"displayName":"Đức Nguyễn Quang","userId":"15255943122151670013"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["print(\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n","print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loss: 121.46%\n","accuracy: 65.05%\n"]}]},{"cell_type":"code","metadata":{"id":"v8O3z4IFmg-G"},"source":[""],"execution_count":null,"outputs":[]}]}